{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mushroom data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from plotnine import ggplot, aes, geom_density, geom_line, geom_point, ggtitle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe, Variables, and Splitting Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"mushrooms.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dataset contains 8124 observations and 23 features\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The whole features are catogrical including the target variable. We have binary claasification, either the mushroom is poisonous or edible.\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data set has no missing values\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the uniques values of each feature\n",
    "for i in data.columns:\n",
    "  print(i, data[i].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we have deleted one of the columns that has no connection with the rest of the data.\n",
    "data.drop(['veil-type'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_col(col, hue=None, color=['red', 'lightgreen'], labels=None):\n",
    "    fig, ax = plt.subplots(figsize=(15, 7))\n",
    "    sns.countplot(col, hue=hue, palette=color, saturation=0.6, data=data, dodge=True, ax=ax)\n",
    "    ax.set(title = f\"Mushroom {col.title()} Quantity\", xlabel=f\"{col.title()}\", ylabel=\"Quantity\")\n",
    "    if labels!=None:\n",
    "        ax.set_xticklabels(labels)\n",
    "    if hue!=None:\n",
    "        ax.legend(('Poisonous', 'Edible'), loc=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have approximate balance values of the target variable\n",
    "class_dict = ('Poisonous', 'Edible')\n",
    "plot_col(col='class', labels=class_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.groupby('class').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw diffrent cap variables along with target variable\n",
    "shape_dict = {\"bell\":\"b\",\"conical\":\"c\",\"convex\":\"x\",\"flat\":\"f\", \"knobbed\":\"k\",\"sunken\":\"s\"}\n",
    "labels = ('convex', 'bell', 'sunken', 'flat', 'knobbed', 'conical')\n",
    "plot_col(col='cap-shape', hue='class', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dict = {\"brown\":\"n\",\"yellow\":\"y\", \"blue\":\"w\", \"gray\":\"g\", \"red\":\"e\",\"pink\":\"p\",\n",
    "              \"orange\":\"b\", \"purple\":\"u\", \"black\":\"c\", \"green\":\"r\"}\n",
    "plot_col(col='cap-color', hue='class', labels=color_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surface_dict = {\"smooth\":\"s\", \"scaly\":\"y\", \"fibrous\":\"f\",\"grooves\":\"g\"}\n",
    "plot_col(col='cap-surface', hue='class', labels=surface_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(order, a_dict):    \n",
    "    labels = []\n",
    "    for values in order:\n",
    "        for key, value in a_dict.items():\n",
    "            if values == value:\n",
    "                labels.append(key)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mushroom Population & Habitat Percentage\n",
    "pop_dict = {\"abundant\":\"a\",\"clustered\":\"c\",\"numerous\":\"n\",\"scattered\":\"s\",\"several\":\"v\",\"solitary\":\"y\"}\n",
    "hab_dict = {\"grasses\":\"g\",\"leaves\":\"l\",\"meadows\":\"m\",\"paths\":\"p\",\"urban\":\"u\",\"waste\":\"w\",\"woods\":\"d\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(15, 10))\n",
    "order = list(data['population'].value_counts().index)\n",
    "pop_labels = get_labels(order, pop_dict)\n",
    "explode = (0.0,0.01,0.02,0.03,0.04,0.05)\n",
    "data['population'].value_counts().plot.pie(explode=explode , autopct='%1.1f%%', labels=pop_labels, shadow=True, ax=ax)\n",
    "ax.set_title('Mushroom Population Type Percentange');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(15, 10))\n",
    "order = list(data['habitat'].value_counts().index)\n",
    "hab_labels = get_labels(order, hab_dict)\n",
    "explode = (0.0,0.01,0.02,0.03,0.04,0.05, 0.06)\n",
    "data['habitat'].value_counts().plot.pie(explode=explode, autopct='%1.1f%%', labels=hab_labels, shadow=True, ax=ax)\n",
    "ax.set_title('Mushroom Habitat Type Percentange');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bulding Machine Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression using the One Hot Encoding technique and an 80/20 split strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate target and features columns\n",
    "y= data[\"class\"].values\n",
    "X= data.drop([\"class\"],axis=1)\n",
    "\n",
    "# split the dataset into train and test sets (80-20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=11)\n",
    "#print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate logistic regression on the Mushroom dataset with an one-hot encoding\n",
    "\n",
    "# one-hot encode input variables\n",
    "onehot_encoder = OneHotEncoder()\n",
    "onehot_encoder.fit(X_train)\n",
    "X_train = onehot_encoder.transform(X_train)\n",
    "X_test = onehot_encoder.transform(X_test)\n",
    "\n",
    "# encode target variable\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "y_train = label_encoder.transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# define the model\n",
    "model = LogisticRegression()\n",
    "# fit on the training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# evaluate the model\n",
    "print(\"Test Accuracy: {}%\".format(round(accuracy_score(y_test, model.predict(X_test))*100,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-nearest Neighbors Algorithm using the One Hot Encoding technique and an 80/20 split strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate KNN on the Mushroom dataset with an one-hot encoding\n",
    "\n",
    "# create KNN model object\n",
    "knn = KNeighborsRegressor()\n",
    "\n",
    "# define loss function\n",
    "loss = 'neg_root_mean_squared_error'\n",
    "\n",
    "# create 10 fold CV object\n",
    "kfold = KFold(n_splits=10, random_state=11, shuffle=True)\n",
    "\n",
    "# Create grid of hyperparameter values\n",
    "hyper_grid = {'n_neighbors': range(2, 17)}\n",
    "\n",
    "# Tune a knn model using grid search\n",
    "grid_search = GridSearchCV(knn, hyper_grid, cv=kfold, scoring=loss)\n",
    "results = grid_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model's k value\n",
    "results.best_estimator_.get_params().get('n_neighbors')\n",
    "\n",
    "# Cross validated grid search\n",
    "\n",
    "# Plot all RMSE results\n",
    "all_rmse = pd.DataFrame({'k': range(2, 17), \n",
    "                         'RMSE': np.abs(results.cv_results_['mean_test_score'])})\n",
    "\n",
    "(ggplot(all_rmse, aes(x='k', y='RMSE'))\n",
    " + geom_line()\n",
    " + geom_point()\n",
    " + ggtitle(\"Cross validated grid search results\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build knn on the best k value and make the prdeiction & accuaracy\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "print(\"Test Accuracy: {}%\".format(round(accuracy_score(y_test, knn.predict(X_test))*100,2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression using the One Hot Encoding technique and an 70/30 split strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate target and features columns\n",
    "y= data[\"class\"].values\n",
    "X= data.drop([\"class\"],axis=1)\n",
    "\n",
    "# split the dataset into train and test sets (80-20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=11)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate logistic regression on the Mushroom dataset with an one-hot encoding\n",
    "\n",
    "# one-hot encode input variables\n",
    "onehot_encoder = OneHotEncoder()\n",
    "onehot_encoder.fit(X_train)\n",
    "X_train = onehot_encoder.transform(X_train)\n",
    "X_test = onehot_encoder.transform(X_test)\n",
    "\n",
    "# encode target variable\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "y_train = label_encoder.transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# define the model\n",
    "model = LogisticRegression()\n",
    "# fit on the training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# evaluate the model\n",
    "print(\"Test Accuracy: {}%\".format(round(accuracy_score(y_test, model.predict(X_test))*100,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-nearest Neighbors Algorithm using the One Hot Encoding technique and an 70/30 split strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate KNN on the Mushroom dataset with an one-hot encoding\n",
    "\n",
    "# create KNN model object\n",
    "knn = KNeighborsRegressor()\n",
    "\n",
    "# define loss function\n",
    "loss = 'neg_root_mean_squared_error'\n",
    "\n",
    "# create 10 fold CV object\n",
    "kfold = KFold(n_splits=10, random_state=123, shuffle=True)\n",
    "\n",
    "# Create grid of hyperparameter values\n",
    "hyper_grid = {'n_neighbors': range(2, 17)}\n",
    "\n",
    "# Tune a knn model using grid search\n",
    "grid_search = GridSearchCV(knn, hyper_grid, cv=kfold, scoring=loss)\n",
    "results = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model's k value\n",
    "results.best_estimator_.get_params().get('n_neighbors')\n",
    "\n",
    "# Cross validated grid search\n",
    "\n",
    "# Plot all RMSE results\n",
    "all_rmse = pd.DataFrame({'k': range(2, 17), \n",
    "                         'RMSE': np.abs(results.cv_results_['mean_test_score'])})\n",
    "\n",
    "(ggplot(all_rmse, aes(x='k', y='RMSE'))\n",
    " + geom_line()\n",
    " + geom_point()\n",
    " + ggtitle(\"Cross validated grid search results\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build knn on the best k value and make the prdeiction & accuaracy\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "knn.fit(X_train, y_train)\n",
    "print(\"Test Accuracy: {}%\".format(round(accuracy_score(y_test, knn.predict(X_test))*100,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-nearest Neighbors Algorithm using the LabelEncoder technique and an 80/20 split strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "for col in data.columns:\n",
    "    data = data.apply(le.fit_transform)\n",
    "    \n",
    "# separate target and features columns\n",
    "dfX = data.iloc[:,1:]\n",
    "dfY = data['class']\n",
    "\n",
    "# split the dataset into train and test sets (80-20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(dfX, dfY, test_size=0.2, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate KNN on the Mushroom dataset with LabelEncoder\n",
    "\n",
    "# create KNN model object\n",
    "knn = KNeighborsRegressor()\n",
    "\n",
    "# define loss function\n",
    "loss = 'neg_root_mean_squared_error'\n",
    "\n",
    "# create 10 fold CV object\n",
    "kfold = KFold(n_splits=10, random_state=123, shuffle=True)\n",
    "\n",
    "# Create grid of hyperparameter values\n",
    "hyper_grid = {'n_neighbors': range(2, 17)}\n",
    "\n",
    "# Tune a knn model using grid search\n",
    "grid_search = GridSearchCV(knn, hyper_grid, cv=kfold, scoring=loss)\n",
    "results = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model's k value\n",
    "results.best_estimator_.get_params().get('n_neighbors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build knn on the best k value and make the prdeiction & accuaracy\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "print(\"Test Accuracy: {}%\".format(round(accuracy_score(y_test, knn.predict(X_test))*100,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression using the LabelEncoder technique and an 80/20 split strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate logistic regression on the Mushroom dataset with LabelEncoder\n",
    "\n",
    "# define the model\n",
    "model = LogisticRegression(solver='newton-cg')\n",
    "# fit on the training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# evaluate the model\n",
    "print(\"Test Accuracy: {}%\".format(round(accuracy_score(y_test, model.predict(X_test))*100,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression using the LabelEncoder technique and an 70/30 split strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "for col in data.columns:\n",
    "    data = data.apply(le.fit_transform)\n",
    "    \n",
    "# separate target and features columns\n",
    "dfX = data.iloc[:,1:]\n",
    "dfY = data['class']\n",
    "\n",
    "# split the dataset into train and test sets (80-20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(dfX, dfY, test_size=0.3, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate logistic regression on the Mushroom dataset with LabelEncoder\n",
    "\n",
    "# define the model\n",
    "model = LogisticRegression(solver='newton-cg')\n",
    "# fit on the training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# evaluate the model\n",
    "print(\"Test Accuracy: {}%\".format(round(accuracy_score(y_test, model.predict(X_test))*100,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-nearest Neighbors Algorithm using the LabelEncoder technique and an 70/30 split strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate KNN on the Mushroom dataset with LabelEncoder\n",
    "\n",
    "# create KNN model object\n",
    "knn = KNeighborsRegressor()\n",
    "\n",
    "# define loss function\n",
    "loss = 'neg_root_mean_squared_error'\n",
    "\n",
    "# create 10 fold CV object\n",
    "kfold = KFold(n_splits=10, random_state=123, shuffle=True)\n",
    "\n",
    "# Create grid of hyperparameter values\n",
    "hyper_grid = {'n_neighbors': range(2, 17)}\n",
    "\n",
    "# Tune a knn model using grid search\n",
    "grid_search = GridSearchCV(knn, hyper_grid, cv=kfold, scoring=loss)\n",
    "results1 = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model's k value\n",
    "results1.best_estimator_.get_params().get('n_neighbors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build knn on the best k value and make the prdeiction & accuaracy\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "knn.fit(X_train, y_train)\n",
    "print(\"Test Accuracy: {}%\".format(round(accuracy_score(y_test, knn.predict(X_test))*100,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-nearest Neighbors Algorithm and Logistic Regression using the LabelEncoder technique and 5/10-kfold split strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data processing \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "for col in data.columns:\n",
    "    data = data.apply(le.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfX = data.iloc[:,1:]\n",
    "dfY = data['class']\n",
    "dfX.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "skf = KFold(n_splits=5, shuffle=True)\n",
    "#skf = KFold(n_splits=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "accurecy_report = dict()\n",
    "def trainwith(modelname):\n",
    "    print(f'using model: {modelname} '.center(100,'='),'\\n')\n",
    "    idx = 0\n",
    "    model_accurecy =[]\n",
    "    for _train,_test in skf.split(dfX, dfY):\n",
    "        idx += 1\n",
    "        print(f'Fold Number {idx} '.center(100,'='), '\\n')\n",
    "        modelname.fit(dfX.iloc[_train],dfY.iloc[_train])\n",
    "        print('Confusion Matrix'.center(70,'-'), '\\n')\n",
    "        ypred = modelname.predict(dfX.iloc[_test])\n",
    "        print(confusion_matrix(dfY.iloc[_test],ypred), '\\n')\n",
    "        print('Classification Report'.center(70,'-'), '\\n')\n",
    "        print(classification_report(dfY.iloc[_test],ypred))\n",
    "        model_accurecy.append(accuracy_score(dfY.iloc[_test],ypred))\n",
    "    print('='*100)\n",
    "    print('The average accurecy of this model is {:.02f}%'.format(np.array(model_accurecy).mean()*100))\n",
    "    accurecy_report[modelname] = round(np.array(model_accurecy).mean()*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_model = KNeighborsClassifier(n_neighbors=2)\n",
    "trainwith(KNN_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_model = LogisticRegression(solver='newton-cg')\n",
    "trainwith(LR_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-nearest Neighbors Algorithm and Logistic Regression using the One hot Encoding technique and 5/10-kfold split strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot label encoding\n",
    "features = data.iloc[:,1:]\n",
    "features = pd.get_dummies(features)\n",
    "target = data.iloc[:,0].replace({'p': 0, 'e': 1})\n",
    "print('First 5 rows of new encoded feature columns:\\n',features.head())\n",
    "print('First 5 rows of new encoded target class of mushroom poisonous = 0 edible = 1:\\n',target.head())\n",
    "dfX = features.values\n",
    "dfY = target.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "accurecy_report = dict()\n",
    "def trainwith(modelname):\n",
    "    print(f'using model: {modelname} '.center(100,'='),'\\n')\n",
    "    idx = 0\n",
    "    model_accurecy =[]\n",
    "    for _train,_test in skf.split(dfX, dfY):\n",
    "        idx += 1\n",
    "        print(f'Fold Number {idx} '.center(100,'='), '\\n')\n",
    "        modelname.fit(dfX[_train],dfY[_train])\n",
    "        print('Confusion Matrix'.center(70,'-'), '\\n')\n",
    "        ypred = modelname.predict(dfX[_test])\n",
    "        print(confusion_matrix(dfY[_test],ypred), '\\n')\n",
    "        print('Classification Report'.center(70,'-'), '\\n')\n",
    "        print(classification_report(dfY[_test],ypred))\n",
    "        model_accurecy.append(accuracy_score(dfY[_test],ypred))\n",
    "    print('='*100)\n",
    "    print('The average accurecy of this model is {:.02f}%'.format(np.array(model_accurecy).mean()*100))\n",
    "    accurecy_report[modelname] = round(np.array(model_accurecy).mean()*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_model = KNeighborsClassifier(n_neighbors=2)\n",
    "trainwith(KNN_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_model = LogisticRegression(solver='newton-cg')\n",
    "trainwith(LR_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
